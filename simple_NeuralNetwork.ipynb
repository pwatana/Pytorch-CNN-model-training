{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flatplanet/Pytorch-Tutorial-Youtube/blob/main/simple_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGOD8SzOPQAk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# if needed (for efficiency purposes), open this file in colab and access the free GPU\n",
        "# otherwsie, the code will run on the CPU\n",
        "# set up local mac GPU offered by pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnDj8FLiRSxO"
      },
      "outputs": [],
      "source": [
        "# Create a Model Class that inherits nn.Module\n",
        "# nn.Module stands for neural network module\n",
        "# this class will have 3 layers\n",
        "# 1. input layer\n",
        "# 2. hidden layer\n",
        "# 3. output layer\n",
        "# each layer will have a number of neurons\n",
        "# the input layer will have 4 neurons\n",
        "# the hidden layer will have 8 neurons\n",
        "# the output layer will have 3 neurons\n",
        "# the forward method will be used to pass the input data through the model\n",
        "# the forward method will use the ReLU activation function\n",
        "# the forward method will return the output of the model\n",
        "\n",
        "# the model will be used to classify the iris flowers into 3 classes\n",
        "# the model will be trained using the iris dataset\n",
        "# the model will be evaluated using the test dataset\n",
        "# the model will be saved and loaded for future use\n",
        "\n",
        "class Model(nn.Module):\n",
        "  # Input layer (4 features of the flower) --> \n",
        "  # Hidden Layer 1 (number of neurons) --> \n",
        "  # H2 (n) --> \n",
        "  # output (3 classes)\n",
        "  def __inint__(self, in_features=4, h1=8. h2=9, out_features=3):\n",
        "    # the values chosen for hidden layer is kind of arbitrary\n",
        "    # input and output are determined\n",
        "    super().__init__()\n",
        "    # this stands for the parent\n",
        "    # inintialize the layers\n",
        "    self.fc1 = nn.Linear(in_features, h1)\n",
        "    # fc stands for fully connected\n",
        "    # input feature connected to the first hidden layer\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    # the second hidden layer connected to the first hidden layer\n",
        "    self.out = nn.Linear(h2, out_features)\n",
        "    # lastly, the second hidden layer connected to the output layer\n",
        "\n",
        "# we now need a function that will pass the input data through the model\n",
        "# in other words, just moving things forward through the model\n",
        "# the forward method will use the ReLU activation function\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x)) # push it into first layer\n",
        "    x = F.relu(self.fc2(x)) # into second layer\n",
        "    x = self.out(x) # into output layer\n",
        "    return x # return the output\n",
        "  # you see that x just keeps on moving forward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3O7rymtcT-bD"
      },
      "outputs": [],
      "source": [
        "# Pick a manual seed for randomization\n",
        "torch.manual_seed(41)\n",
        "# Create an instance of model\n",
        "model = Model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "11Q8PWnaUVYj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WzV4PfT2xhF"
      },
      "outputs": [],
      "source": [
        "# This is the iris dataset\n",
        "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
        "my_df = pd.read_csv(url)\n",
        "# we can directly read the data from the url using pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r9iQSTSP3X2F",
        "outputId": "1badc81e-f5d3-4136-f161-53d8ea09a1fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
              "145           6.7          3.0           5.2          2.3  Virginica\n",
              "146           6.3          2.5           5.0          1.9  Virginica\n",
              "147           6.5          3.0           5.2          2.0  Virginica\n",
              "148           6.2          3.4           5.4          2.3  Virginica\n",
              "149           5.9          3.0           5.1          1.8  Virginica"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_df.tail()\n",
        "# see that we have four features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qTcYyxFe3ZHU",
        "outputId": "f43bf80f-638a-4b7f-d87c-da58d75f4c8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal.length</th>\n",
              "      <th>sepal.width</th>\n",
              "      <th>petal.length</th>\n",
              "      <th>petal.width</th>\n",
              "      <th>variety</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
              "0             5.1          3.5           1.4          0.2      0.0\n",
              "1             4.9          3.0           1.4          0.2      0.0\n",
              "2             4.7          3.2           1.3          0.2      0.0\n",
              "3             4.6          3.1           1.5          0.2      0.0\n",
              "4             5.0          3.6           1.4          0.2      0.0\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3      2.0\n",
              "146           6.3          2.5           5.0          1.9      2.0\n",
              "147           6.5          3.0           5.2          2.0      2.0\n",
              "148           6.2          3.4           5.4          2.3      2.0\n",
              "149           5.9          3.0           5.1          1.8      2.0\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change last column from strings to integers\n",
        "# use replace function from pandas\n",
        "# CNN, ML in general works better with numbers right?\n",
        "# Setosa --> 0.0\n",
        "# Versicolor --> 1.0    \n",
        "# Virginica --> 2.0\n",
        "my_df['variety'] = my_df['variety'].replace('Setosa', 0.0)\n",
        "my_df['variety'] = my_df['variety'].replace('Versicolor', 1.0)\n",
        "my_df['variety'] = my_df['variety'].replace('Virginica', 2.0)\n",
        "my_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZCKBrRz3xRE"
      },
      "outputs": [],
      "source": [
        "# Train Test Split!  Set X, y\n",
        "X = my_df.drop('variety', axis=1)\n",
        "y = my_df['variety']\n",
        "# X is the input data/the features (4 features, sepa length/width, petal length/width)\n",
        "# y is the target data\n",
        "# we are dropping the variety column from X, because that is basically the outcome that we are predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvjES9MX4MF1"
      },
      "outputs": [],
      "source": [
        "# Convert these to numpy arrays\n",
        "X = X.values\n",
        "y = y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AkNGTq2e4M40"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRv8t5BV4YQs"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
        "# we split both the input and target data into training and testing data\n",
        "# the test size is 20% of the data, this is usually the standard\n",
        "# we set a random seed for reproduc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eD_LwH6Q46-t"
      },
      "outputs": [],
      "source": [
        "# Convert X features to float tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "# make sure we are always feeding the model with tensors\n",
        "# we are converting the data to tensors, because pytorch works with tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo-sZan65Qgj"
      },
      "outputs": [],
      "source": [
        "# Convert y labels to tensors long\n",
        "# do the same thing, both input and output train and test must be tensors\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DoEoy3SA5mAz"
      },
      "outputs": [],
      "source": [
        "# Set the criterion of model to measure the error, how far off the predictions are from the data\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# this is the loss function, the error function\n",
        "# we want to make sure we visualize the error, so we can see how well the model is doing\n",
        "# we want to minimize the error\n",
        "# Choose Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs), lower our learning rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# so the lower the learning rate, the more accurate the model will be, but the slower it will be\n",
        "# the higher the learning rate, the faster the model will be, but the less accurate\n",
        "# so remember to find the sweet spot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0EJKYEJ6eKz",
        "outputId": "0f714daf-0493-43e9-f058-e7b33fe5e099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 and loss is: 1.125203251838684\n",
            "Epoch 10 and loss is: 1.0097211599349976\n",
            "Epoch 20 and loss is: 0.8162347674369812\n",
            "Epoch 30 and loss is: 0.5859931111335754\n",
            "Epoch 40 and loss is: 0.4003389775753021\n",
            "Epoch 50 and loss is: 0.26794713735580444\n",
            "Epoch 60 and loss is: 0.1796349436044693\n",
            "Epoch 70 and loss is: 0.12165623158216476\n",
            "Epoch 80 and loss is: 0.08606517314910889\n",
            "Epoch 90 and loss is: 0.06522618234157562\n"
          ]
        }
      ],
      "source": [
        "# Train our model!\n",
        "# Epochs? (one run thru all the training data in our network)\n",
        "epochs = 100 # what is the best number of epochs?\n",
        "losses = [] # keep track of the loss\n",
        "# we want to see how the loss changes over time\n",
        "# Looking at the plateau\n",
        "for i in range(epochs):\n",
        "    # Go forward and get a prediction\n",
        "    y_pred = model.forward(X_train) # Get predicted results\n",
        "\n",
        "    # Measure the loss/error, gonna be high at first \n",
        "    loss = criterion(y_pred, y_train) # Predicted values vs the y_train\n",
        "\n",
        "    # Keep track of the loss\n",
        "    losses.append(loss.detach().numpy())\n",
        "\n",
        "    # print every 10 epoch\n",
        "    if i%10 == 0:\n",
        "        print(f'Epoch {i} and loss is: {loss}')\n",
        "\n",
        "    # Do the backpropagation: take the error rate of forward propagration and feed it back \n",
        "    # thru the network to adjust the weights\n",
        "    optimizer.zero_grad() # zero the gradient\n",
        "    loss.backward() # backpropagation\n",
        "    optimizer.step() # update the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "EErRwcHZ6gD6",
        "outputId": "a2ba8134-399d-4a13-e252-29f4b45dd6b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Graph it out!\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel(\"loss/error\")\n",
        "plt.xlabel('Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Dip1EQKV8e8C"
      },
      "outputs": [],
      "source": [
        "# Evaluate Model on Test Data Set (validate model on test set)\n",
        "with torch.no_grad():  # Basically turn off back propogation\n",
        "  y_eval = model.forward(X_test) # X_test are features from our test set, y_eval will be predictions\n",
        "  loss = criterion(y_eval, y_test) # Find the loss or error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKGJ7x_NZN5e",
        "outputId": "59c49944-1a98-44cf-d0e4-8f06a80c0b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.1315)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is the final loss for the test data set, which shows how good our model is\n",
        "# it represent the model's fit on the test data, lower the loss the better it is\n",
        "loss\n",
        "# notice that this value is quite far from the loss we got from the training data\n",
        "# it's way higher than the training loss, but that's okay\n",
        "# because this is the first time the model is seeing this data\n",
        "# as long as the accuracy expected is reached, for example, in this case it has predicted 28 our 30 correctly\n",
        "# let's dive deeper to see how our model did on this data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyntMH5tZOtW",
        "outputId": "889fe499-9325-4879-e031-ff69b065b9de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.)  tensor([-5.8771,  4.4629,  6.5155]) \t 2 \t 2\n",
            "2.)  tensor([-7.5451,  4.1668,  9.7293]) \t 2 \t 2\n",
            "3.)  tensor([-8.4517,  5.1275, 10.2015]) \t 2 \t 2\n",
            "4.)  tensor([-4.3411,  5.6280,  2.5636]) \t 1 \t 1\n",
            "5.)  tensor([-7.1838,  4.8757,  8.3023]) \t 2 \t 2\n",
            "6.)  tensor([-3.3940,  5.3421,  1.2802]) \t 1 \t 1\n",
            "7.)  tensor([-5.9240,  4.9826,  6.0025]) \t 2 \t 2\n",
            "8.)  tensor([-4.2895,  5.7016,  2.3920]) \t 1 \t 1\n",
            "9.)  tensor([-6.5369,  4.9261,  7.1291]) \t 2 \t 2\n",
            "10.)  tensor([-8.0526,  4.4129, 10.3325]) \t 2 \t 2\n",
            "11.)  tensor([-5.6775,  4.9505,  5.6248]) \t 2 \t 2\n",
            "12.)  tensor([ 4.5748, -2.2579, -2.8925]) \t 0 \t 0\n",
            "13.)  tensor([ 4.2646, -2.0055, -2.7342]) \t 0 \t 0\n",
            "14.)  tensor([-2.1081,  4.0482,  0.5803]) \t 1 \t 1\n",
            "15.)  tensor([ 3.4608, -1.2147, -2.3488]) \t 0 \t 0\n",
            "16.)  tensor([-5.4739,  5.1174,  5.0966]) \t 2 \t 1\n",
            "17.)  tensor([ 4.0637, -1.8045, -2.6504]) \t 0 \t 0\n",
            "18.)  tensor([-5.8090,  4.6057,  6.2494]) \t 1 \t 2\n",
            "19.)  tensor([ 4.9250, -2.5763, -3.0545]) \t 0 \t 0\n",
            "20.)  tensor([ 3.4559, -1.2559, -2.3637]) \t 0 \t 0\n",
            "21.)  tensor([-2.6161,  4.5584,  0.8575]) \t 1 \t 1\n",
            "22.)  tensor([-7.7427,  4.7379,  9.4233]) \t 2 \t 2\n",
            "23.)  tensor([ 3.5777, -1.3269, -2.4109]) \t 0 \t 0\n",
            "24.)  tensor([ 4.5445, -2.2478, -2.8698]) \t 0 \t 0\n",
            "25.)  tensor([-2.6548,  4.6138,  0.8825]) \t 1 \t 1\n",
            "26.)  tensor([-3.2832,  5.2189,  1.2163]) \t 1 \t 1\n",
            "27.)  tensor([-4.6527,  5.7790,  2.9302]) \t 1 \t 1\n",
            "28.)  tensor([-2.9436,  4.8858,  1.0381]) \t 1 \t 1\n",
            "29.)  tensor([ 4.5932, -2.2788, -2.8989]) \t 0 \t 0\n",
            "30.)  tensor([-4.5797,  5.4566,  3.1690]) \t 1 \t 1\n",
            "We got 28 correct!\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = model.forward(data)\n",
        "\n",
        "    if y_test[i] == 0:\n",
        "      x = \"Setosa\"\n",
        "    elif y_test[i] == 1:\n",
        "      x = 'Versicolor'\n",
        "    else:\n",
        "      x = 'Virginica'\n",
        "\n",
        "\n",
        "    # Will tell us what type of flower class our network thinks it is\n",
        "    print(f'{i+1}.)  {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    # Correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct +=1\n",
        "\n",
        "print(f'We got {correct} correct!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DJPl2eAmbJiM"
      },
      "outputs": [],
      "source": [
        "new_iris = torch.tensor([4.7, 3.2, 1.3, 0.2])\n",
        "# new flower data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrDdPpEsmPOd",
        "outputId": "28800bc0-b5c0-4a65-ef4f-d850a0f1fc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 4.5445, -2.2478, -2.8698])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  print(model(new_iris))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EcdmzRL7mZ_M"
      },
      "outputs": [],
      "source": [
        "newer_iris = torch.tensor([5.9, 3.0, 5.1, 1.8])\n",
        "# more new flower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPnukBTCmrLs",
        "outputId": "bb09b40e-fc73-410e-8a36-aaa38578e59e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-5.9960,  4.5080,  6.6831])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  print(model(newer_iris))\n",
        "# the model is predicting the new flowers correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc42k-Crmvck"
      },
      "outputs": [],
      "source": [
        "# Save our NN Model\n",
        "torch.save(model.state_dict(), 'my_really_awesome_iris_model.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RKnF7RXnhYz",
        "outputId": "c0d210a5-7b39-46d7-bfdd-91aa678f2cbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the Saved Model\n",
        "new_model = Model()\n",
        "new_model.load_state_dict(torch.load('my_really_awesome_iris_model.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_GTla9nyAa",
        "outputId": "8784f762-4c12-4cf5-c9dc-dfa3fbf3dbe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
              "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
              "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make sure it loaded correctly\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### My summar of creating a simple neural network\n",
        "\n",
        "1. Define model where there is: input, hidden layers (fully connected), and output layer with a forward method that pushes the input through the layers.\n",
        "2. Load and format data into appropriate form so mostly using pandas. \n",
        "3. Define the input and output\n",
        "4. Define input traning and test, output training and test\n",
        "5. Set the loss function criterion and the learning rate\n",
        "6. Train the model, for the number of epochs, while tracking the loss.\n",
        "7. Adjust epochs and learning rate accordingly and apply to test data and see the loss result.\n",
        "8. Trouble shoot/ further dive in by looking at the correctness of the prediction on the test data if necessary (for example, if the loss value is far higher compared to the training).\n",
        "9. Try testing on some new data.\n",
        "10. Save the model.\n",
        "11. Load the model. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMUpEgHNEUhEvvktBMAIcXc",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
